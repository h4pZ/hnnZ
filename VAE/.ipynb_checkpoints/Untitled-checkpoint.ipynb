{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/h4pz/anaconda3/envs/ml/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\"\"\"Implementation of a variational autoencoder in pytorch\n",
    "https://arxiv.org/pdf/1312.6114.pdf\"\"\"\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/home/h4pz/Downloads/fashionmnist/\"\n",
    "\n",
    "train = pd.read_csv(data_path + \"fashion-mnist_train.csv\")\n",
    "test = pd.read_csv(data_path + \"fashion-mnist_test.csv\")\n",
    "\n",
    "X_train = train.drop(\"label\", axis=1).values\n",
    "X_test = test.drop(\"label\", axis=1).values\n",
    "\n",
    "y_train = train[\"label\"].values\n",
    "y_test = test[\"label\"].values\n",
    "\n",
    "del(train, test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-75aa07bb4ed6>, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-75aa07bb4ed6>\"\u001b[0;36m, line \u001b[0;32m46\u001b[0m\n\u001b[0;31m    mu, logvar = self.\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Implementation of a variational autoencoder in pytorch\n",
    "https://arxiv.org/pdf/1312.6114.pdf\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, layers_sizes=(784, 400, 20)):\n",
    "        \"\"\"MODEL DESCRIPTION\"\"\"\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Model parameters.\n",
    "        self.layers_sizes = layers_sizes\n",
    "\n",
    "        # Populating the encoder.\n",
    "        self.encoder_layers = list()\n",
    "\n",
    "        for layer_i in range(len(layers_sizes) - 1):\n",
    "            self.encoder_layers.append(nn.ReLU(nn.Linear(\n",
    "                in_features=layers_sizes[layer_i],\n",
    "                out_features=layers_sizes[layer_i + 1])))\n",
    "\n",
    "        # Populating the decoder.\n",
    "        self.decoder_layers = list()\n",
    "\n",
    "        for layer_i in range(len(layers_sizes) - 1):\n",
    "            self.decoder_layers.append(nn.ReLU(nn.Linear(\n",
    "                in_features=layers_sizes[::-1][layer_i],\n",
    "                out_features=layers_sizes[::-1][layer_i + 1])))\n",
    "\n",
    "        # Assembling the encoder and decoder.\n",
    "        self.encoder = nn.Sequential(*self.encoder_layers)\n",
    "        self.decoder = nn.Sequential(*self.decoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        pass\n",
    "\n",
    "\n",
    "model = VAE()\n",
    "model.to(device)\n",
    "print(model)\n",
    "print(\"Nice\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "model = VAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=784, out_features=400, bias=True)\n",
       "  (fc21): Linear(in_features=400, out_features=20, bias=True)\n",
       "  (fc22): Linear(in_features=400, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=400, bias=True)\n",
       "  (fc4): Linear(in_features=400, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
